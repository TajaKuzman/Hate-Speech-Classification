{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hate Speech Binary Classification","metadata":{}},{"cell_type":"markdown","source":"Import all necessary libraries and install everything you need for training:","metadata":{}},{"cell_type":"markdown","source":"First, enable the GPU - under Accelerator on the right of the site, choose GPU. Be careful to always terminate the session (click the power off button), otherwise it will still be running and you will lose the 30 hours of GPU that you have available per week.","metadata":{}},{"cell_type":"code","source":"# install the libraries necessary for data wrangling, prediction and result analysis\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report, confusion_matrix, f1_score,precision_score, recall_score\nimport torch\nfrom numba import cuda\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.dummy import DummyClassifier","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:13:23.734606Z","iopub.execute_input":"2022-07-01T08:13:23.734983Z","iopub.status.idle":"2022-07-01T08:13:23.741549Z","shell.execute_reply.started":"2022-07-01T08:13:23.734952Z","shell.execute_reply":"2022-07-01T08:13:23.740272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install transformers\n# (this needs to be done on Kaggle each time you start the session)\n!pip install -q transformers","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:22:54.769465Z","iopub.execute_input":"2022-07-01T07:22:54.77004Z","iopub.status.idle":"2022-07-01T07:23:05.790402Z","shell.execute_reply.started":"2022-07-01T07:22:54.770005Z","shell.execute_reply":"2022-07-01T07:23:05.789232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install the simpletransformers\n!pip install -q simpletransformers\nfrom simpletransformers.classification import ClassificationModel","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:23:05.794408Z","iopub.execute_input":"2022-07-01T07:23:05.79483Z","iopub.status.idle":"2022-07-01T07:23:37.867044Z","shell.execute_reply.started":"2022-07-01T07:23:05.794784Z","shell.execute_reply":"2022-07-01T07:23:37.865845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import the data\nYou might need to upload the data (click on the Add data button on the left of the site). I have uploaded the first version of the data that I created (see the 1-Data-Preparation.ipynb spreadsheet): \"hatespeechdataset\". If you change the Google Sheet, you can reprocess it by running the data preparation spreadsheet and upload the new version of it (go to the dataset description (https://www.kaggle.com/datasets/tajakuz/hatespeechdataset), click on the three dots and choose \"New Version)","metadata":{}},{"cell_type":"code","source":"# Upload the binary hate speech dataset\nhs_dataset = pd.read_csv(\"/kaggle/input/hatespeechdataset/hatespeech_binary_dataset.csv\", sep=\"\\t\", index_col=0)\nhs_dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:23:37.869143Z","iopub.execute_input":"2022-07-01T07:23:37.870358Z","iopub.status.idle":"2022-07-01T07:23:37.937028Z","shell.execute_reply.started":"2022-07-01T07:23:37.870315Z","shell.execute_reply":"2022-07-01T07:23:37.935973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See the statistics on the dataset\nhs_dataset.describe()","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:23:37.93972Z","iopub.execute_input":"2022-07-01T07:23:37.940177Z","iopub.status.idle":"2022-07-01T07:23:37.958984Z","shell.execute_reply.started":"2022-07-01T07:23:37.94014Z","shell.execute_reply":"2022-07-01T07:23:37.958037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the labels\nLABELS = [0,1]","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:23:37.960487Z","iopub.execute_input":"2022-07-01T07:23:37.960849Z","iopub.status.idle":"2022-07-01T07:23:37.965614Z","shell.execute_reply.started":"2022-07-01T07:23:37.960815Z","shell.execute_reply":"2022-07-01T07:23:37.964476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First, let's split the dataset into train and test split based on the column \"split\" (all newly annotated instances are in the test split)\n\nhs_train = hs_dataset[hs_dataset[\"split\"] == \"train\"]\n\nhs_test = hs_dataset[hs_dataset[\"split\"] == \"test\"]\n\n# See the size of the splits\nhs_train.shape, hs_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:24:32.980267Z","iopub.execute_input":"2022-07-01T07:24:32.980659Z","iopub.status.idle":"2022-07-01T07:24:32.997539Z","shell.execute_reply.started":"2022-07-01T07:24:32.980624Z","shell.execute_reply":"2022-07-01T07:24:32.996154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Delete the column \"split\"\nhs_train = hs_train.drop(columns=[\"split\"])\nhs_test = hs_test.drop(columns=[\"split\"])","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:25:30.544979Z","iopub.execute_input":"2022-07-01T07:25:30.545708Z","iopub.status.idle":"2022-07-01T07:25:31.014487Z","shell.execute_reply.started":"2022-07-01T07:25:30.545671Z","shell.execute_reply":"2022-07-01T07:25:31.011465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check how the splits look like\nhs_train.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:25:36.094387Z","iopub.execute_input":"2022-07-01T07:25:36.095382Z","iopub.status.idle":"2022-07-01T07:25:36.105725Z","shell.execute_reply.started":"2022-07-01T07:25:36.095335Z","shell.execute_reply":"2022-07-01T07:25:36.104596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check how the splits look like\nhs_test.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:25:47.179369Z","iopub.execute_input":"2022-07-01T07:25:47.179729Z","iopub.status.idle":"2022-07-01T07:25:47.189066Z","shell.execute_reply.started":"2022-07-01T07:25:47.179698Z","shell.execute_reply":"2022-07-01T07:25:47.188121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's analyze the distribution of labels in both splits\nhs_train.labels.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:27:00.583236Z","iopub.execute_input":"2022-07-01T07:27:00.584262Z","iopub.status.idle":"2022-07-01T07:27:00.593177Z","shell.execute_reply.started":"2022-07-01T07:27:00.584211Z","shell.execute_reply":"2022-07-01T07:27:00.591897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hs_test.labels.value_counts(normalize=True)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:27:08.850371Z","iopub.execute_input":"2022-07-01T07:27:08.850729Z","iopub.status.idle":"2022-07-01T07:27:08.860322Z","shell.execute_reply.started":"2022-07-01T07:27:08.850699Z","shell.execute_reply":"2022-07-01T07:27:08.858502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a file to save results into (you can find it under Data: Output). Be careful, run this step only once to not overwrite the results file.\nresults = []\n\nwith open(\"HateSpeech-Experiments-Results.json\", \"w\") as results_file:\n    json.dump(results,results_file, indent= \"\")","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:29:26.63734Z","iopub.execute_input":"2022-07-01T07:29:26.638264Z","iopub.status.idle":"2022-07-01T07:29:26.643893Z","shell.execute_reply.started":"2022-07-01T07:29:26.638227Z","shell.execute_reply":"2022-07-01T07:29:26.642851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In each next step (after the first experiment), open the results file instead of creating a new results file:\nwith open(\"./HateSpeech-Experiments-Results.json\", \"r\") as results_file:\n    previous_results = json.load(results_file)\n\n# See the results\nprevious_results","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:29:28.988565Z","iopub.execute_input":"2022-07-01T07:29:28.988941Z","iopub.status.idle":"2022-07-01T07:29:28.997197Z","shell.execute_reply.started":"2022-07-01T07:29:28.988908Z","shell.execute_reply":"2022-07-01T07:29:28.996137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and testing - dummy classifier\n\nLet's first apply a baseline classifier which predicts the most frequent class to each instance, to see what is the baseline score.","metadata":{"execution":{"iopub.execute_input":"2022-06-29T12:11:51.221801Z","iopub.status.busy":"2022-06-29T12:11:51.221298Z","iopub.status.idle":"2022-06-29T12:11:51.233411Z","shell.execute_reply":"2022-06-29T12:11:51.231818Z","shell.execute_reply.started":"2022-06-29T12:11:51.22176Z"}}},{"cell_type":"code","source":"# Create X_train and Y_train parts, used for sci kit learning\n# We need to split each split (test and train) into an object with just texts and object with just labels\nX_train = list(hs_train.text)\nY_train = list(hs_train.labels)\n\nX_test = list(hs_test.text)\nY_test = list(hs_test.labels)\n\n# See their sizes\nlen(X_train), len(Y_train), len(X_test), len(Y_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:26:07.232765Z","iopub.execute_input":"2022-07-01T07:26:07.233468Z","iopub.status.idle":"2022-07-01T07:26:07.243544Z","shell.execute_reply.started":"2022-07-01T07:26:07.233429Z","shell.execute_reply":"2022-07-01T07:26:07.242468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use the Dummy Classifier, with the strategy \"most_frequent\"\ndummy_clf = DummyClassifier(strategy=\"most_frequent\")\n\n# Train the model\ndummy_clf.fit(X_train, Y_train)\n\n#Get the predictions\ny_pred = dummy_clf.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:27:53.162681Z","iopub.execute_input":"2022-07-01T07:27:53.163034Z","iopub.status.idle":"2022-07-01T07:27:53.16955Z","shell.execute_reply.started":"2022-07-01T07:27:53.163002Z","shell.execute_reply":"2022-07-01T07:27:53.168521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare the predictions with true values (Y_test)\nmicro = f1_score(Y_test, y_pred, labels=LABELS, average =\"micro\")\nmacro = f1_score(Y_test, y_pred, labels=LABELS, average =\"macro\")\naccuracy = round(metrics.accuracy_score(Y_test, y_pred),3)\nprint(f\"Micro F1: {micro:.3f}, Macro F1: {macro:.3f}, Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:27:55.115093Z","iopub.execute_input":"2022-07-01T07:27:55.115456Z","iopub.status.idle":"2022-07-01T07:27:55.129004Z","shell.execute_reply.started":"2022-07-01T07:27:55.115425Z","shell.execute_reply":"2022-07-01T07:27:55.127242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the results:\nrezdict = {\n    \"model\": \"dummy\",\n    \"microF1\": micro,\n    \"macroF1\": macro,\n    \"accuracy\": accuracy,\n    }\nprevious_results.append(rezdict)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:29:32.485586Z","iopub.execute_input":"2022-07-01T07:29:32.485947Z","iopub.status.idle":"2022-07-01T07:29:32.491726Z","shell.execute_reply.started":"2022-07-01T07:29:32.485916Z","shell.execute_reply":"2022-07-01T07:29:32.490594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"previous_results","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:29:34.269083Z","iopub.execute_input":"2022-07-01T07:29:34.26945Z","iopub.status.idle":"2022-07-01T07:29:34.275825Z","shell.execute_reply.started":"2022-07-01T07:29:34.26942Z","shell.execute_reply":"2022-07-01T07:29:34.274769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training and testing - Transformer model","metadata":{}},{"cell_type":"markdown","source":"We will use the basic English monolingual BERT model: https://huggingface.co/bert-base-uncased","metadata":{}},{"cell_type":"markdown","source":"You can find more documentation on how to use Simple Transformer models here: https://simpletransformers.ai/docs/usage/\n\nFor the hyperparameters (args), I used the ones that worked for me before, but you can see the entire list here: https://simpletransformers.ai/docs/usage/#configuring-a-simple-transformers-model","metadata":{}},{"cell_type":"code","source":"# Define the model\nbertbase_model = ClassificationModel(\n        \"bert\", \"bert-base-cased\",\n        num_labels=2,\n        use_cuda=True,\n        args= {\n    # Here, we have much more instances than in Experiment 1, so we can use less epochs.\n    \"num_train_epochs\": 20,\n    \"labels_list\": LABELS,\n    \"learning_rate\": 1e-5,\n    # We'll use a smaller max_seq_length (we could set it up to 512), because we have short texts\n    \"max_seq_length\": 128,\n    # Use this to mute the long output that tells you how the model proceeds.\n    \"silent\": True,\n    # Below are just some additional hyperparameters that we found that help with memory errors\n    \"save_steps\": -1,\n    \"overwrite_output_dir\": True,\n    \"no_cache\": True,\n    \"no_save\": True,\n    }\n    )","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:29:52.396747Z","iopub.execute_input":"2022-07-01T07:29:52.397125Z","iopub.status.idle":"2022-07-01T07:30:18.992546Z","shell.execute_reply.started":"2022-07-01T07:29:52.39709Z","shell.execute_reply":"2022-07-01T07:30:18.99142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train the model on train data - this will take some time\nbertbase_model.train_model(hs_train)\n\nprint(\"Training is finished!\")","metadata":{"execution":{"iopub.status.busy":"2022-07-01T07:30:18.99801Z","iopub.execute_input":"2022-07-01T07:30:19.000751Z","iopub.status.idle":"2022-07-01T07:54:32.549288Z","shell.execute_reply.started":"2022-07-01T07:30:19.000711Z","shell.execute_reply":"2022-07-01T07:54:32.54823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Test the model - this will take some time\n\n# Get the true labels\ny_true = hs_test.labels\n\n# Calculate the model's predictions on test\ndef make_prediction(input_string):\n    return bertbase_model.predict([input_string])[0][0]\n\ny_pred = hs_test.text.apply(make_prediction)\n\nprint(\"Testing is finished!\")","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-07-01T07:55:12.907072Z","iopub.execute_input":"2022-07-01T07:55:12.907815Z","iopub.status.idle":"2022-07-01T07:58:19.322429Z","shell.execute_reply.started":"2022-07-01T07:55:12.907779Z","shell.execute_reply":"2022-07-01T07:58:19.321146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# See the predictions\ny_pred","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:01:48.362236Z","iopub.execute_input":"2022-07-01T08:01:48.362856Z","iopub.status.idle":"2022-07-01T08:01:48.371172Z","shell.execute_reply.started":"2022-07-01T08:01:48.362816Z","shell.execute_reply":"2022-07-01T08:01:48.370002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add the information about the predictions to the main table with information about implicitness\n\n# Open the main table\nmain_sheet = pd.read_csv(\"/kaggle/input/hatespeechdataset/hate-speech-prepared-spreadsheet.csv\", sep=\"\\t\", index_col = 0)\n\nmain_sheet.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:01:57.093055Z","iopub.execute_input":"2022-07-01T08:01:57.093461Z","iopub.status.idle":"2022-07-01T08:01:57.175268Z","shell.execute_reply.started":"2022-07-01T08:01:57.093428Z","shell.execute_reply":"2022-07-01T08:01:57.174102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add the information about predictions to the main sheet\n\nmain_sheet[\"binary-hs-y_pred\"] = y_pred\n\n# Add also the labels, converted to integers\nmain_sheet[\"binary-hs-y_true\"] = y_true","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:02:07.725997Z","iopub.execute_input":"2022-07-01T08:02:07.726501Z","iopub.status.idle":"2022-07-01T08:02:07.736196Z","shell.execute_reply.started":"2022-07-01T08:02:07.726457Z","shell.execute_reply":"2022-07-01T08:02:07.734928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main_sheet.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:02:14.296161Z","iopub.execute_input":"2022-07-01T08:02:14.296654Z","iopub.status.idle":"2022-07-01T08:02:14.334174Z","shell.execute_reply.started":"2022-07-01T08:02:14.296613Z","shell.execute_reply":"2022-07-01T08:02:14.332297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the scores\nmacro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\nmicro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\naccuracy = round(metrics.accuracy_score(y_true, y_pred),3)\nprint(f\"Macro f1: {macro:0.3}, Micro f1: {micro:0.3}, Accuracy: {accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:02:41.746574Z","iopub.execute_input":"2022-07-01T08:02:41.746973Z","iopub.status.idle":"2022-07-01T08:02:41.761072Z","shell.execute_reply.started":"2022-07-01T08:02:41.746942Z","shell.execute_reply":"2022-07-01T08:02:41.759766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the confusion matrix:\ncm = confusion_matrix(y_true, y_pred, labels=LABELS)\nplt.figure(figsize=(9, 9))\nplt.imshow(cm, cmap=\"Oranges\")\nfor (i, j), z in np.ndenumerate(cm):\n    plt.text(j, i, '{:d}'.format(z), ha='center', va='center')\n#classNames = LABELS\nclassNames = [\"Acceptable\", \"Hate Speech\"]\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\ntick_marks = np.arange(len(classNames))\nplt.xticks(tick_marks, classNames, rotation=90)\nplt.yticks(tick_marks, classNames)\nplt.title(\"Binary Hate Speech Classification\")\n\nplt.tight_layout()\nfig1 = plt.gcf()\nplt.show()\nplt.draw()\nfig1.savefig(f\"Confusion-matrix-binary-hate-speech-general.png\",dpi=100)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:02:59.109786Z","iopub.execute_input":"2022-07-01T08:02:59.110439Z","iopub.status.idle":"2022-07-01T08:02:59.458723Z","shell.execute_reply.started":"2022-07-01T08:02:59.110404Z","shell.execute_reply":"2022-07-01T08:02:59.457561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the results:\nrezdict = {\n    \"model\": \"BERT\",\n    \"epoch\": 30,\n    \"microF1\": micro,\n    \"macroF1\": macro,\n    \"accuracy\": accuracy,\n    }\nprevious_results.append(rezdict)\n\n#Save intermediate results (just in case)\nbackup = []\nbackup.append(rezdict)\nwith open(f\"backup-results.json\", \"w\") as backup_file:\n    json.dump(backup,backup_file, indent= \"\")","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:05:24.986288Z","iopub.execute_input":"2022-07-01T08:05:24.986879Z","iopub.status.idle":"2022-07-01T08:05:24.99432Z","shell.execute_reply.started":"2022-07-01T08:05:24.986843Z","shell.execute_reply":"2022-07-01T08:05:24.993245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compare the results by creating a dataframe from the previous_results dictionary:\nresults_df = pd.DataFrame(previous_results)\n\nresults_df","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:05:29.568573Z","iopub.execute_input":"2022-07-01T08:05:29.569115Z","iopub.status.idle":"2022-07-01T08:05:29.592717Z","shell.execute_reply.started":"2022-07-01T08:05:29.569014Z","shell.execute_reply":"2022-07-01T08:05:29.591804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(results_df.drop(columns=[\"epoch\"]).to_markdown())","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:05:47.12889Z","iopub.execute_input":"2022-07-01T08:05:47.129272Z","iopub.status.idle":"2022-07-01T08:05:47.563679Z","shell.execute_reply.started":"2022-07-01T08:05:47.129238Z","shell.execute_reply":"2022-07-01T08:05:47.561551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that BERT performs better than the baseline and that we get the best results when we train the model for 20 epochs.","metadata":{}},{"cell_type":"code","source":"# Add the end, save the file with results:\nwith open(\"./HateSpeech-Experiments-Results-Annotation-split.json\", \"w\") as final_results_file:\n    json.dump(previous_results,final_results_file, indent= \"\")","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:11:58.396537Z","iopub.execute_input":"2022-07-01T08:11:58.396931Z","iopub.status.idle":"2022-07-01T08:11:58.403229Z","shell.execute_reply.started":"2022-07-01T08:11:58.396899Z","shell.execute_reply":"2022-07-01T08:11:58.40202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Comparison of prediction scores based on implicitness","metadata":{}},{"cell_type":"markdown","source":"Let's compare how the prediction scores vary based on the implicitness/explicitness of the text.","metadata":{}},{"cell_type":"code","source":"main_sheet.head()","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:12:37.036901Z","iopub.execute_input":"2022-07-01T08:12:37.037587Z","iopub.status.idle":"2022-07-01T08:12:37.055172Z","shell.execute_reply.started":"2022-07-01T08:12:37.037549Z","shell.execute_reply":"2022-07-01T08:12:37.054129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the test instances in implicit and explicit set and calculate the evaluation scores for each set.\nimpl_test = main_sheet[main_sheet[\"Implicit\"] == 1.0]\nexpl_test = main_sheet[main_sheet[\"Implicit\"] == 0.0]\n\n# View the sizes of the splits\nimpl_test.shape, expl_test.shape","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:12:50.672529Z","iopub.execute_input":"2022-07-01T08:12:50.673155Z","iopub.status.idle":"2022-07-01T08:12:50.683103Z","shell.execute_reply.started":"2022-07-01T08:12:50.673085Z","shell.execute_reply":"2022-07-01T08:12:50.682082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impl_test.tail()","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:12:55.571537Z","iopub.execute_input":"2022-07-01T08:12:55.571899Z","iopub.status.idle":"2022-07-01T08:12:55.590179Z","shell.execute_reply.started":"2022-07-01T08:12:55.571867Z","shell.execute_reply":"2022-07-01T08:12:55.588988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# First calculations revealed one error in annotation - acceptable speech annotated with implicitness\nimpl_test[impl_test[\"binary-hate-speech\"] == \"Acceptable speech\"]","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:15:57.272798Z","iopub.execute_input":"2022-07-01T08:15:57.273185Z","iopub.status.idle":"2022-07-01T08:15:57.289733Z","shell.execute_reply.started":"2022-07-01T08:15:57.273146Z","shell.execute_reply":"2022-07-01T08:15:57.288425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's remove this instance from the dataframe on which we'll calculate the scores\n\nimpl_test = impl_test.drop(741, axis = 0)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:19:29.951349Z","iopub.execute_input":"2022-07-01T08:19:29.951991Z","iopub.status.idle":"2022-07-01T08:19:29.958007Z","shell.execute_reply.started":"2022-07-01T08:19:29.951954Z","shell.execute_reply":"2022-07-01T08:19:29.957032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's check if it's removed\nimpl_test.loc[740:743]","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:19:31.743484Z","iopub.execute_input":"2022-07-01T08:19:31.743938Z","iopub.status.idle":"2022-07-01T08:19:31.776805Z","shell.execute_reply.started":"2022-07-01T08:19:31.743894Z","shell.execute_reply":"2022-07-01T08:19:31.775727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calculate the scores for each of the two splits - create a function\ndef calculate_scores(split, split_name):\n    # Create a list of y_true and y_pred labels for each split\n    y_true = list(split[\"binary-hs-y_true\"])\n    y_pred = list(split[\"binary-hs-y_pred\"])\n    \n    #Calculate the scores for each split\n    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n    micro = f1_score(y_true, y_pred, labels=LABELS,  average=\"micro\")\n    accuracy = round(metrics.accuracy_score(y_true, y_pred),3)\n    precision = precision_score(y_true, y_pred)\n    recall = recall_score(y_true, y_pred)\n    \n    # F1 score (only for the HS instances, acceptable instances not included)\n    F1 = 2 * (precision * recall) / (precision + recall)\n    \n    print(f\"Scores for {split_name}: Macro f1: {macro:0.3}, Micro f1: {micro:0.3}, Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, HS label F1 score: {F1}\")\n    \n    # Plot the confusion matrix:\n    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n    plt.figure(figsize=(9, 9))\n    plt.imshow(cm, cmap=\"Oranges\")\n    for (i, j), z in np.ndenumerate(cm):\n        plt.text(j, i, '{:d}'.format(z), ha='center', va='center')\n    classNames = [\"Acceptable\", \"Hate Speech\"]\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    tick_marks = np.arange(len(classNames))\n    plt.xticks(tick_marks, classNames, rotation=90)\n    plt.yticks(tick_marks, classNames)\n    plt.title(f\"Binary Hate Speech Classification - {split_name}\")\n\n    plt.tight_layout()\n    fig1 = plt.gcf()\n    plt.show()\n    plt.draw()\n    fig1.savefig(f\"Confusion-matrix-binary-hate-speech-{split_name}.png\",dpi=100)","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:19:54.680876Z","iopub.execute_input":"2022-07-01T08:19:54.681551Z","iopub.status.idle":"2022-07-01T08:19:54.693965Z","shell.execute_reply.started":"2022-07-01T08:19:54.681512Z","shell.execute_reply":"2022-07-01T08:19:54.692693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Run the function on the two splits\ncalculate_scores(impl_test, \"implicit hate speech\")\ncalculate_scores(expl_test, \"explicit hate speech\")","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:19:57.43298Z","iopub.execute_input":"2022-07-01T08:19:57.433746Z","iopub.status.idle":"2022-07-01T08:19:58.046132Z","shell.execute_reply.started":"2022-07-01T08:19:57.433711Z","shell.execute_reply":"2022-07-01T08:19:58.045124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save the extended sheet\nmain_sheet.to_csv(\"hate-speech-prepared-spreadsheet-binary-prediction-annotation-split.csv\", sep = \"\\t\")","metadata":{"execution":{"iopub.status.busy":"2022-07-01T08:20:11.967487Z","iopub.execute_input":"2022-07-01T08:20:11.967851Z","iopub.status.idle":"2022-07-01T08:20:12.071409Z","shell.execute_reply.started":"2022-07-01T08:20:11.96782Z","shell.execute_reply":"2022-07-01T08:20:12.070293Z"},"trusted":true},"execution_count":null,"outputs":[]}]}